{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5f45a",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7213a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>insurance</th>\n",
       "      <th>religion</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>diagnosis_summary</th>\n",
       "      <th>procedure_summary</th>\n",
       "      <th>prescriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>F</td>\n",
       "      <td>2094-03-05</td>\n",
       "      <td>Anemia of other chronic disease; Anticoagulant...</td>\n",
       "      <td>Hemodialysis; Injection or infusion of oxazoli...</td>\n",
       "      <td>Acetaminophen, Alteplase (Catheter Clearance),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10011</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>Private</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>F</td>\n",
       "      <td>2090-06-05</td>\n",
       "      <td>Acute and subacute necrosis of liver; Chronic ...</td>\n",
       "      <td>Parenteral infusion of concentrated nutritiona...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10013</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>F</td>\n",
       "      <td>2038-09-03</td>\n",
       "      <td>Atrial fibrillation; Cardiogenic shock; Mitral...</td>\n",
       "      <td>Arterial catheterization</td>\n",
       "      <td>Acetaminophen, Alteplase (Catheter Clearance),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10017</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>F</td>\n",
       "      <td>2075-09-21</td>\n",
       "      <td>Acute posthemorrhagic anemia; Closed fracture ...</td>\n",
       "      <td>Partial shoulder replacement; Transfusion of p...</td>\n",
       "      <td>1/2 NS, Acetaminophen, Albuterol, Albuterol 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10019</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>M</td>\n",
       "      <td>2114-06-20</td>\n",
       "      <td>Acute alcoholic hepatitis; Acute kidney failur...</td>\n",
       "      <td>Continuous invasive mechanical ventilation for...</td>\n",
       "      <td>1/2 NS, Albumin 25% (12.5gm), Artificial Tear ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id               ethnicity insurance  religion gender         dob  \\\n",
       "0       10006  BLACK/AFRICAN AMERICAN  Medicare  CATHOLIC      F  2094-03-05   \n",
       "1       10011   UNKNOWN/NOT SPECIFIED   Private  CATHOLIC      F  2090-06-05   \n",
       "2       10013   UNKNOWN/NOT SPECIFIED  Medicare  CATHOLIC      F  2038-09-03   \n",
       "3       10017                   WHITE  Medicare  CATHOLIC      F  2075-09-21   \n",
       "4       10019                   WHITE  Medicare  CATHOLIC      M  2114-06-20   \n",
       "\n",
       "                                   diagnosis_summary  \\\n",
       "0  Anemia of other chronic disease; Anticoagulant...   \n",
       "1  Acute and subacute necrosis of liver; Chronic ...   \n",
       "2  Atrial fibrillation; Cardiogenic shock; Mitral...   \n",
       "3  Acute posthemorrhagic anemia; Closed fracture ...   \n",
       "4  Acute alcoholic hepatitis; Acute kidney failur...   \n",
       "\n",
       "                                   procedure_summary  \\\n",
       "0  Hemodialysis; Injection or infusion of oxazoli...   \n",
       "1  Parenteral infusion of concentrated nutritiona...   \n",
       "2                           Arterial catheterization   \n",
       "3  Partial shoulder replacement; Transfusion of p...   \n",
       "4  Continuous invasive mechanical ventilation for...   \n",
       "\n",
       "                                       prescriptions  \n",
       "0  Acetaminophen, Alteplase (Catheter Clearance),...  \n",
       "1                                                NaN  \n",
       "2  Acetaminophen, Alteplase (Catheter Clearance),...  \n",
       "3  1/2 NS, Acetaminophen, Albuterol, Albuterol 0....  \n",
       "4  1/2 NS, Albumin 25% (12.5gm), Artificial Tear ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv(\"final_flat_dataset.csv\")  # replace with actual path\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a4bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: Fill text fields\n",
    "df['diagnosis_summary'] = df['diagnosis_summary'].fillna(\"\")\n",
    "df['ethnicity'] = df['ethnicity'].fillna(\"\")\n",
    "df['insurance'] = df['insurance'].fillna(\"\")\n",
    "df['religion'] = df['religion'].fillna(\"\")\n",
    "df['gender'] = df['gender'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f035e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70, 125), (70, 83))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform features\n",
    "X = preprocessor.fit_transform(df)\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(df['procedure_summary'])\n",
    "\n",
    "# One-hot encode target for MLP\n",
    "y_onehot = np.eye(len(np.unique(y_encoded)))[y_encoded]\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e93c9",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4598a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Manual MLP Components\n",
    "# -----------------------------\n",
    "\n",
    "# Activation Functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    # y_true must be one-hot encoded\n",
    "    m = y_true.shape[0]\n",
    "    log_likelihood = -np.log(y_pred[range(m), y_true.argmax(axis=1)] + 1e-9)\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10caa5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MLP Initialization\n",
    "def init_mlp(input_dim, hidden_dim, output_dim):\n",
    "    params = {\n",
    "        \"W1\": np.random.randn(input_dim, hidden_dim) * 0.01,\n",
    "        \"b1\": np.zeros((1, hidden_dim)),\n",
    "        \"W2\": np.random.randn(hidden_dim, output_dim) * 0.01,\n",
    "        \"b2\": np.zeros((1, output_dim))\n",
    "    }\n",
    "    return params\n",
    "\n",
    "# Forward Pass\n",
    "def forward_pass(X, params):\n",
    "    Z1 = np.dot(X, params[\"W1\"]) + params[\"b1\"]\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, params[\"W2\"]) + params[\"b2\"]\n",
    "    A2 = softmax(Z2)\n",
    "    cache = {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n",
    "    return A2, cache\n",
    "\n",
    "# Backward Pass (Backprop)\n",
    "def backward_pass(X, y_true, params, cache):\n",
    "    m = X.shape[0]\n",
    "    dZ2 = cache[\"A2\"] - y_true\n",
    "    dW2 = np.dot(cache[\"A1\"].T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "    dA1 = np.dot(dZ2, params[\"W2\"].T)\n",
    "    dZ1 = dA1 * relu_derivative(cache[\"Z1\"])\n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return grads\n",
    "\n",
    "# Update Parameters\n",
    "def update_params(params, grads, lr):\n",
    "    params[\"W1\"] -= lr * grads[\"dW1\"]\n",
    "    params[\"b1\"] -= lr * grads[\"db1\"]\n",
    "    params[\"W2\"] -= lr * grads[\"dW2\"]\n",
    "    params[\"b2\"] -= lr * grads[\"db2\"]\n",
    "    return params\n",
    "\n",
    "# One Training Step \n",
    "def train_step(X, y_true, params, lr=0.01):\n",
    "    y_pred, cache = forward_pass(X, params)\n",
    "    loss = cross_entropy_loss(y_pred, y_true)\n",
    "    grads = backward_pass(X, y_true, params, cache)\n",
    "    params = update_params(params, grads, lr)\n",
    "    return loss, params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29812b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2baef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 83)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape  \n",
    "y_train.shape   #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24d76238",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 32               # You can tune this\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "params = init_mlp(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f88a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.4118\n",
      "Epoch 2, Loss: 4.4100\n",
      "Epoch 3, Loss: 4.4083\n",
      "Epoch 4, Loss: 4.4067\n",
      "Epoch 5, Loss: 4.4050\n",
      "Epoch 6, Loss: 4.4033\n",
      "Epoch 7, Loss: 4.4017\n",
      "Epoch 8, Loss: 4.4001\n",
      "Epoch 9, Loss: 4.3985\n",
      "Epoch 10, Loss: 4.3969\n",
      "Epoch 11, Loss: 4.3953\n",
      "Epoch 12, Loss: 4.3937\n",
      "Epoch 13, Loss: 4.3921\n",
      "Epoch 14, Loss: 4.3906\n",
      "Epoch 15, Loss: 4.3890\n",
      "Epoch 16, Loss: 4.3875\n",
      "Epoch 17, Loss: 4.3859\n",
      "Epoch 18, Loss: 4.3844\n",
      "Epoch 19, Loss: 4.3829\n",
      "Epoch 20, Loss: 4.3813\n",
      "Epoch 21, Loss: 4.3798\n",
      "Epoch 22, Loss: 4.3783\n",
      "Epoch 23, Loss: 4.3767\n",
      "Epoch 24, Loss: 4.3752\n",
      "Epoch 25, Loss: 4.3736\n",
      "Epoch 26, Loss: 4.3721\n",
      "Epoch 27, Loss: 4.3705\n",
      "Epoch 28, Loss: 4.3690\n",
      "Epoch 29, Loss: 4.3674\n",
      "Epoch 30, Loss: 4.3658\n",
      "Epoch 31, Loss: 4.3642\n",
      "Epoch 32, Loss: 4.3625\n",
      "Epoch 33, Loss: 4.3609\n",
      "Epoch 34, Loss: 4.3592\n",
      "Epoch 35, Loss: 4.3575\n",
      "Epoch 36, Loss: 4.3557\n",
      "Epoch 37, Loss: 4.3540\n",
      "Epoch 38, Loss: 4.3522\n",
      "Epoch 39, Loss: 4.3503\n",
      "Epoch 40, Loss: 4.3484\n",
      "Epoch 41, Loss: 4.3465\n",
      "Epoch 42, Loss: 4.3445\n",
      "Epoch 43, Loss: 4.3424\n",
      "Epoch 44, Loss: 4.3403\n",
      "Epoch 45, Loss: 4.3381\n",
      "Epoch 46, Loss: 4.3359\n",
      "Epoch 47, Loss: 4.3335\n",
      "Epoch 48, Loss: 4.3311\n",
      "Epoch 49, Loss: 4.3286\n",
      "Epoch 50, Loss: 4.3260\n",
      "Epoch 51, Loss: 4.3233\n",
      "Epoch 52, Loss: 4.3205\n",
      "Epoch 53, Loss: 4.3176\n",
      "Epoch 54, Loss: 4.3145\n",
      "Epoch 55, Loss: 4.3114\n",
      "Epoch 56, Loss: 4.3081\n",
      "Epoch 57, Loss: 4.3047\n",
      "Epoch 58, Loss: 4.3011\n",
      "Epoch 59, Loss: 4.2974\n",
      "Epoch 60, Loss: 4.2935\n",
      "Epoch 61, Loss: 4.2895\n",
      "Epoch 62, Loss: 4.2854\n",
      "Epoch 63, Loss: 4.2810\n",
      "Epoch 64, Loss: 4.2765\n",
      "Epoch 65, Loss: 4.2718\n",
      "Epoch 66, Loss: 4.2669\n",
      "Epoch 67, Loss: 4.2619\n",
      "Epoch 68, Loss: 4.2567\n",
      "Epoch 69, Loss: 4.2512\n",
      "Epoch 70, Loss: 4.2456\n",
      "Epoch 71, Loss: 4.2398\n",
      "Epoch 72, Loss: 4.2338\n",
      "Epoch 73, Loss: 4.2276\n",
      "Epoch 74, Loss: 4.2211\n",
      "Epoch 75, Loss: 4.2145\n",
      "Epoch 76, Loss: 4.2076\n",
      "Epoch 77, Loss: 4.2005\n",
      "Epoch 78, Loss: 4.1931\n",
      "Epoch 79, Loss: 4.1855\n",
      "Epoch 80, Loss: 4.1776\n",
      "Epoch 81, Loss: 4.1694\n",
      "Epoch 82, Loss: 4.1609\n",
      "Epoch 83, Loss: 4.1521\n",
      "Epoch 84, Loss: 4.1430\n",
      "Epoch 85, Loss: 4.1335\n",
      "Epoch 86, Loss: 4.1236\n",
      "Epoch 87, Loss: 4.1134\n",
      "Epoch 88, Loss: 4.1027\n",
      "Epoch 89, Loss: 4.0915\n",
      "Epoch 90, Loss: 4.0800\n",
      "Epoch 91, Loss: 4.0679\n",
      "Epoch 92, Loss: 4.0553\n",
      "Epoch 93, Loss: 4.0423\n",
      "Epoch 94, Loss: 4.0286\n",
      "Epoch 95, Loss: 4.0144\n",
      "Epoch 96, Loss: 3.9997\n",
      "Epoch 97, Loss: 3.9845\n",
      "Epoch 98, Loss: 3.9687\n",
      "Epoch 99, Loss: 3.9522\n",
      "Epoch 100, Loss: 3.9352\n"
     ]
    }
   ],
   "source": [
    "# X.shape = (num_samples, num_features)\n",
    "# y.shape = (num_samples, num_classes), one-hot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = init_mlp(input_dim=X.shape[1], hidden_dim=64, output_dim=y.shape[1])\n",
    "\n",
    "for epoch in range(100):\n",
    "    loss, params = train_step(X_train, y_train, params, lr=0.1)\n",
    "    \n",
    "    # Optional: Track training accuracy\n",
    "    y_pred_probs, _ = forward_pass(X_train, params)\n",
    "    accuracy = np.mean(np.argmax(y_pred_probs, axis=1) == np.argmax(y_train, axis=1))\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdf587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
